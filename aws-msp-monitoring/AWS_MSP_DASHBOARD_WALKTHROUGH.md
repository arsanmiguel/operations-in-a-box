# AWS MSP Dashboard Creation Walkthrough

## üéØ Complete Beginner's Guide to Building Monitoring Dashboards

This guide assumes **zero prior experience** with monitoring or dashboards. Follow these exact steps to create professional monitoring dashboards for your customers.

---

## üìã Prerequisites

‚úÖ **Monitoring stack deployed** using `./aws-msp-monitoring-installer.sh`  
‚úÖ **Grafana running** at http://localhost:3000  
‚úÖ **Login credentials** from `CREDENTIALS.md` file  
‚úÖ **Optional: Plugins installed** for enhanced functionality (see Plugin Guide below)
‚úÖ **Python dependencies** auto-installed (PyYAML, requests) during setup  

---

## üöÄ Part 1: Getting Started (5 minutes)

### Step 1: Access Grafana
1. **Open your web browser**
2. **Go to:** http://localhost:3000
3. **Login with:**
   - Username: `admin`
   - Password: (from your `CREDENTIALS.md` file)

### Step 2: Navigate to Dashboards
1. **Click the menu icon** (‚ò∞) in the top-left corner
2. **Click "Dashboards"** in the left sidebar
3. **Click "New"** button (blue button, top-right)
4. **Select "New Dashboard"**

üéâ **You're now in the dashboard editor!**

---

## üìä Part 2: Create Your First Dashboard (10 minutes)

### Step 3: Add Your First Panel (CPU Monitoring)

#### 3.1 Create the Panel
1. **Click "Add visualization"** (big blue button)
2. **Select "Prometheus"** as your data source
3. **You'll see a query editor at the bottom**

#### 3.2 Configure CPU Monitoring
1. **In the query box, type exactly:**
   ```
   system_cpu_usage
   ```
2. **Press Enter** or click "Run queries"
3. **You should see a line graph appear!**

> üí° **Tip**: If no data appears, wait 30 seconds for metrics to populate, then refresh the panel.

#### 3.3 Customize the Panel
1. **Panel title**: Click the panel title and change it to "CPU Usage"
2. **Y-axis label**: In the right panel, find "Axes" ‚Üí "Left Y" ‚Üí "Label" ‚Üí type "Percentage"
3. **Unit**: Set "Unit" to "Percent (0-100)"
4. **Color**: Choose your preferred color scheme

**üéØ Expected Result**: You now have a live CPU usage graph!
3. **You should see a graph appear!**

#### 3.3 Customize the Panel
1. **Panel title:** Click "Panel Title" at the top, change to: `CPU Utilization`
2. **Panel type:** On the right sidebar, ensure "Time series" is selected
3. **Units:** In right sidebar, find "Standard options" ‚Üí "Unit" ‚Üí Select "Percent (0-100)"
4. **Color thresholds:** 
   - Find "Thresholds" in right sidebar
   - Click "Add threshold"
   - Set: Green (0), Yellow (70), Red (85)

#### 3.4 Save the Panel
1. **Click "Apply"** (top-right blue button)

üéâ **Your first CPU monitoring panel is complete!**

---

## üíæ Part 3: Add Disk I/O Monitoring (10 minutes)

### Step 4: Add Second Panel

#### 4.1 Create New Panel
1. **Click "Add"** (+ icon) in the top toolbar
2. **Select "Visualization"**
3. **Select "Prometheus"** data source again

#### 4.2 Configure Disk Read Monitoring
1. **In the query box, type:**
   ```
   disk_read_mbps
   ```
2. **Press Enter**
3. **Click "Add query"** (+ Query button)
4. **In the second query box, type:**
   ```
   disk_write_mbps
   ```
5. **Press Enter**

#### 4.3 Customize Disk I/O Panel
1. **Panel title:** Change to `Disk I/O Activity`
2. **Units:** Right sidebar ‚Üí "Unit" ‚Üí "Data rate" ‚Üí "megabytes/sec"
3. **Legend:** In right sidebar, find "Legend" ‚Üí "Display mode" ‚Üí "Table"
4. **Panel size:** Drag the bottom-right corner to make it wider

#### 4.4 Save the Panel
1. **Click "Apply"**

---

## üö® Part 4: Create High CPU Alert Panel (5 minutes)

### Step 5: Add Alert Panel

#### 5.1 Create Alert Panel
1. **Click "Add" ‚Üí "Visualization"**
2. **Select "Prometheus"**

#### 5.2 Configure Alert Query
1. **Query box:**
   ```
   cpu_utilization_percent > 85
   ```
2. **Press Enter**

#### 5.3 Customize Alert Panel
1. **Panel title:** `üö® HIGH CPU ALERT`
2. **Visualization type:** Right sidebar ‚Üí Change to "Stat"
3. **Color mode:** Right sidebar ‚Üí "Color mode" ‚Üí "Background"
4. **Thresholds:** 
   - Green (null), Red (1)
5. **Text size:** Right sidebar ‚Üí "Text size" ‚Üí "Large"

#### 5.4 Save Alert Panel
1. **Click "Apply"**

---

## üíæ Part 5: Save Your Dashboard (2 minutes)

### Step 6: Save Everything

#### 6.1 Save Dashboard
1. **Click the save icon** (üíæ) in the top toolbar
2. **Dashboard name:** `Customer Infrastructure Monitoring`
3. **Description:** `CPU, Disk I/O, and Alert monitoring for customer systems`
4. **Click "Save"**

üéâ **Your complete monitoring dashboard is saved!**

---

## üìà Part 6: Generate Test Data (5 minutes)

### Step 7: Populate with Data

#### 7.1 Generate Sample Data
1. **Open terminal/command prompt**
2. **Navigate to your monitoring directory:**
   ```bash
   cd [your-customer-name]-monitoring
   ```
3. **Run data generator:**
   ```bash
   python3 ../aws_msp_demo_data_generator.py
   ```
4. **Wait 2-3 minutes for data to populate**

#### 7.2 View Live Data
1. **Go back to Grafana**
2. **Refresh your dashboard** (üîÑ icon)
3. **You should see live data in all panels!**

---

## üé® Part 7: Advanced Customization (Optional)

### Step 8: Make It Look Professional

#### 8.1 Arrange Panels
1. **Drag panels** to rearrange them
2. **Resize panels** by dragging corners
3. **Suggested layout:**
   - CPU panel: Top-left (wide)
   - Disk I/O: Top-right (wide)  
   - Alert panel: Bottom (full width)

#### 8.2 Add Time Controls
1. **Top-right corner:** Set time range to "Last 1 hour"
2. **Auto-refresh:** Set to "5s" for live updates

#### 8.3 Add Dashboard Description
1. **Click dashboard settings** (‚öôÔ∏è gear icon)
2. **Add description:** Brief explanation for your customer
3. **Save changes**

---

## üîß Part 8: Common Customizations

### Adding More Metrics

#### Network Monitoring
**Query:** `network_in_gbps` and `network_out_gbps`  
**Panel type:** Time series  
**Units:** Data rate ‚Üí gigabytes/sec  

#### Memory Usage
**Query:** `memory_utilization_percent`  
**Panel type:** Gauge  
**Units:** Percent (0-100)  
**Thresholds:** Green (0), Yellow (80), Red (90)  

#### System Load
**Query:** `system_load_average`  
**Panel type:** Stat  
**Units:** Short  

### Creating Alerts

#### High CPU Alert
1. **Panel menu** (‚ãØ) ‚Üí "Edit"
2. **Alert tab** ‚Üí "Create Alert"
3. **Condition:** `cpu_utilization_percent > 85`
4. **Notification:** Set up email/Slack integration

---

## üéØ Part 9: Customer Handoff Checklist

### What to Provide Your Customer

#### 9.1 Access Information
- ‚úÖ **Grafana URL:** http://localhost:3000
- ‚úÖ **Login credentials** (from CREDENTIALS.md)
- ‚úÖ **Dashboard link** (copy from browser)

#### 9.2 Basic Training (5 minutes)
1. **Show them how to:**
   - Navigate between dashboards
   - Change time ranges
   - Refresh data
   - Read the metrics

#### 9.3 Documentation
- ‚úÖ **Screenshot** of the completed dashboard
- ‚úÖ **Brief explanation** of each panel
- ‚úÖ **Contact info** for support

---

## üÜò Troubleshooting Guide

### No Data Showing?
1. **Check time range** - Set to "Last 1 hour"
2. **Run data generator** again
3. **Verify services running:** `docker compose ps`
4. **Wait 30 seconds** and refresh

### Query Errors?
1. **Check spelling** of metric names exactly
2. **Ensure Prometheus** data source is selected
3. **Try simpler query** first: just `cpu_utilization_percent`

### Panel Not Updating?
1. **Set auto-refresh** to 5s or 10s
2. **Check dashboard time range**
3. **Manually refresh** browser

### Can't Save Dashboard?
1. **Check permissions** - ensure you're logged in as admin
2. **Try different name** - avoid special characters
3. **Refresh page** and try again

---

## üéì Next Steps for Advanced Users

### Level 2: Advanced Dashboards
- **Multi-server monitoring** (grouping by server)
- **Custom time ranges** and comparisons
- **Calculated metrics** (ratios, percentages)
- **Template variables** for dynamic filtering

### Level 3: Production Features
- **Alert notifications** (email, Slack, PagerDuty)
- **Dashboard sharing** and permissions
- **Data retention** and archiving
- **High availability** setup

---

## üìû Support

### Getting Help
- **Documentation:** Check other AWS MSP guide files
- **Community:** Grafana community forums
- **Professional:** Contact your AWS MSP partner

### Common Resources
- **Grafana Documentation:** https://grafana.com/docs/
- **Prometheus Queries:** https://prometheus.io/docs/prometheus/latest/querying/
- **Dashboard Examples:** https://grafana.com/grafana/dashboards/

---

## ‚úÖ Success Checklist

By the end of this walkthrough, you should have:

- [ ] **Logged into Grafana** successfully
- [ ] **Created a new dashboard** with 3 panels
- [ ] **CPU monitoring panel** showing utilization percentage
- [ ] **Disk I/O panel** showing read/write activity  
- [ ] **Alert panel** for high CPU conditions
- [ ] **Generated test data** to populate charts
- [ ] **Saved the dashboard** with a descriptive name
- [ ] **Customized appearance** and layout
- [ ] **Set up auto-refresh** for live monitoring
- [ ] **Documented access info** for customer handoff

üéâ **Congratulations! You've built a professional monitoring dashboard from scratch!**

---

*This walkthrough typically takes 30-45 minutes for complete beginners. Advanced users can complete it in 15-20 minutes.*

---

## üîå Part 10: Connect External Applications (API Integration)

### Step 9: Understanding the Metrics API

Your monitoring system includes a **secure REST API** that external applications can use to send metrics data. This allows any application, service, or script to push monitoring data into your dashboards.

#### 9.1 API Basics
- **Endpoint:** `http://localhost:8080/api/metrics`
- **Method:** `POST`
- **Authentication:** API Key (from CREDENTIALS.md)
- **Format:** JSON
- **Rate Limits:** 100 requests/hour, 10 requests/minute

#### 9.2 Get Your API Key
1. **Open your monitoring directory**
2. **Find `CREDENTIALS.md` file**
3. **Copy the API Key** (long string starting with letters/numbers)

### Step 10: Basic API Integration Examples

#### 10.1 Simple Curl Example
```bash
# Replace YOUR_API_KEY with actual key from CREDENTIALS.md
curl -X POST http://localhost:8080/api/metrics \
  -H "X-API-Key: YOUR_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "app_name": "my-application",
    "metric_name": "user_logins",
    "value": 25
  }'
```

#### 10.2 Python Application Integration
```python
import requests
import json

# Configuration
API_URL = "http://localhost:8080/api/metrics"
API_KEY = "your-api-key-from-credentials-file"

def send_metric(app_name, metric_name, value):
    """Send a metric to the monitoring system"""
    headers = {
        "X-API-Key": API_KEY,
        "Content-Type": "application/json"
    }
    
    data = {
        "app_name": app_name,
        "metric_name": metric_name,
        "value": value
    }
    
    response = requests.post(API_URL, headers=headers, json=data)
    
    if response.status_code == 200:
        print(f"‚úÖ Metric sent: {metric_name} = {value}")
    else:
        print(f"‚ùå Error: {response.status_code}")

# Example usage in your application
send_metric("web-app", "page_views", 150)
send_metric("web-app", "user_registrations", 5)
send_metric("web-app", "cpu_usage_percent", 45.2)
```

#### 10.3 JavaScript/Node.js Integration
```javascript
const axios = require('axios');

// Configuration
const API_URL = 'http://localhost:8080/api/metrics';
const API_KEY = 'your-api-key-from-credentials-file';

async function sendMetric(appName, metricName, value) {
    try {
        const response = await axios.post(API_URL, {
            app_name: appName,
            metric_name: metricName,
            value: value
        }, {
            headers: {
                'X-API-Key': API_KEY,
                'Content-Type': 'application/json'
            }
        });
        
        console.log(`‚úÖ Metric sent: ${metricName} = ${value}`);
    } catch (error) {
        console.error(`‚ùå Error: ${error.response?.status || error.message}`);
    }
}

// Example usage
sendMetric('api-service', 'requests_per_minute', 120);
sendMetric('api-service', 'response_time_ms', 250);
sendMetric('api-service', 'error_rate_percent', 2.1);
```

#### 10.4 Java Application Integration
```java
import java.net.http.HttpClient;
import java.net.http.HttpRequest;
import java.net.http.HttpResponse;
import java.net.URI;

public class MetricsClient {
    private static final String API_URL = "http://localhost:8080/api/metrics";
    private static final String API_KEY = "your-api-key-from-credentials-file";
    
    public static void sendMetric(String appName, String metricName, double value) {
        try {
            String json = String.format(
                "{\"app_name\":\"%s\",\"metric_name\":\"%s\",\"value\":%.2f}",
                appName, metricName, value
            );
            
            HttpRequest request = HttpRequest.newBuilder()
                .uri(URI.create(API_URL))
                .header("X-API-Key", API_KEY)
                .header("Content-Type", "application/json")
                .POST(HttpRequest.BodyPublishers.ofString(json))
                .build();
            
            HttpClient client = HttpClient.newHttpClient();
            HttpResponse<String> response = client.send(request, 
                HttpResponse.BodyHandlers.ofString());
            
            if (response.statusCode() == 200) {
                System.out.println("‚úÖ Metric sent: " + metricName + " = " + value);
            } else {
                System.out.println("‚ùå Error: " + response.statusCode());
            }
        } catch (Exception e) {
            System.out.println("‚ùå Error: " + e.getMessage());
        }
    }
    
    // Example usage
    public static void main(String[] args) {
        sendMetric("java-app", "system_memory_usage", 75.2);
        sendMetric("java-app", "active_connections", 45);
        sendMetric("java-app", "system_response_time", 125.3);
    }
}
```

### Step 11: Common Integration Patterns

#### 11.1 Web Application Metrics
```python
# In your web application (Flask/Django/etc.)
from flask import Flask, request
import time

app = Flask(__name__)

@app.route('/api/users')
def get_users():
    start_time = time.time()
    
    # Your application logic here
    users = get_user_data()
    
    # Send metrics
    response_time = (time.time() - start_time) * 1000
    send_metric("web-api", "response_time_ms", response_time)
    send_metric("web-api", "users_fetched", len(users))
    
    return users
```

#### 11.2 Database Monitoring
```python
# Monitor database performance
import psycopg2
import time

def monitor_database_query():
    start_time = time.time()
    
    # Execute your database query
    conn = psycopg2.connect(database="mydb")
    cursor = conn.execute("SELECT COUNT(*) FROM users")
    result = cursor.fetchone()
    
    # Send metrics
    query_time = (time.time() - start_time) * 1000
    send_metric("database", "query_time_ms", query_time)
    send_metric("database", "user_count", result[0])
    
    conn.close()
```

#### 11.3 System Resource Monitoring
```python
import psutil
import time

def monitor_system_resources():
    """Monitor and send system metrics every 60 seconds"""
    while True:
        # CPU Usage
        cpu_percent = psutil.cpu_percent(interval=1)
        send_metric("system", "cpu_utilization_percent", cpu_percent)
        
        # Memory Usage
        memory = psutil.virtual_memory()
        send_metric("system", "memory_utilization_percent", memory.percent)
        
        # Disk Usage
        disk = psutil.disk_usage('/')
        disk_percent = (disk.used / disk.total) * 100
        send_metric("system", "disk_utilization_percent", disk_percent)
        
        # Network I/O
        network = psutil.net_io_counters()
        send_metric("system", "network_bytes_sent", network.bytes_sent)
        send_metric("system", "network_bytes_received", network.bytes_recv)
        
        time.sleep(60)  # Wait 60 seconds
```

### Step 12: Creating Custom Dashboards for Your Metrics

#### 12.1 Add Your Application Metrics to Dashboard
1. **Go to your Grafana dashboard**
2. **Add new panel**
3. **Use your custom metric names:**
   - `user_logins` for login tracking
   - `page_views` for web analytics
   - `response_time_ms` for performance
   - `error_rate_percent` for reliability

#### 12.2 Business Metrics Examples
```
# E-commerce metrics
orders_completed
revenue_dollars
cart_abandonment_rate
inventory_low_alerts

# SaaS application metrics
active_users
subscription_renewals
feature_usage_count
support_tickets_created

# API service metrics
requests_per_minute
error_rate_percent
average_response_time
rate_limit_hits
```

### Step 13: Production Integration Best Practices

#### 13.1 Error Handling
```python
def send_metric_safely(app_name, metric_name, value):
    """Send metric with proper error handling"""
    try:
        send_metric(app_name, metric_name, value)
    except requests.exceptions.RequestException as e:
        # Log error but don't crash application
        print(f"Metrics API unavailable: {e}")
    except Exception as e:
        print(f"Unexpected error sending metric: {e}")
```

#### 13.2 Batch Metrics for Performance
```python
def send_metrics_batch(metrics_list):
    """Send multiple metrics in one request (if API supports it)"""
    # For now, send individually with small delay
    for metric in metrics_list:
        send_metric(metric['app'], metric['name'], metric['value'])
        time.sleep(0.1)  # Respect rate limits
```

#### 13.3 Metric Naming Conventions
```
# Good metric names (clear and consistent)
‚úÖ system_cpu_usage
‚úÖ system_memory_usage  
‚úÖ system_response_time
‚úÖ system_error_rate

# Avoid these patterns
‚ùå cpu (unclear units)
‚ùå mem_use (abbreviations)
‚ùå time (too generic)
‚ùå errors (no time context)
```

### Step 14: Testing Your Integration

#### 14.1 Test API Connection
```bash
# Test 1: Basic connectivity
curl -X POST http://localhost:8080/api/metrics \
  -H "X-API-Key: YOUR_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{"app_name": "test", "metric_name": "test_metric", "value": 1}'

# Expected response: {"status": "success"}
```

#### 14.2 Verify Data in Dashboard
1. **Send test metric** using curl command above
2. **Go to Grafana dashboard**
3. **Add new panel** with query: `test_metric`
4. **You should see your test data point**

#### 14.3 Load Testing
```python
# Test rate limits and performance
import time
import threading

def send_test_metrics():
    for i in range(20):  # Send 20 metrics
        send_metric("load-test", "test_counter", i)
        time.sleep(0.5)  # 2 per second

# Run multiple threads to test rate limiting
for _ in range(3):
    threading.Thread(target=send_test_metrics).start()
```

---

## üîå Part 14: Plugin System Integration

### Step 15: Understanding the Plugin Architecture

The AWS MSP monitoring stack includes a powerful plugin system with **18 plugins across 6 categories**. Plugins extend your monitoring capabilities without modifying the core stack.

#### 15.1 Plugin Categories Available
- **üöÄ Performance & Scale** (3 plugins) - Federation, HA, Auto-scaling
- **üõ°Ô∏è Advanced Security** (3 plugins) - SAML/OAuth, Certificates, Network segmentation  
- **‚òÅÔ∏è Cloud Integration** (3 plugins) - AWS CloudWatch, Auto-Discovery, Cost optimization
- **ü§ñ AI/ML Features** (3 plugins) - Anomaly detection, Predictive alerts, Auto-remediation
- **üìä Advanced Analytics** (3 plugins) - Business Intelligence, ELK stack, APM monitoring
- **üîß DevOps Automation** (3 plugins) - Infrastructure as Code, CI/CD, GitOps

#### 15.2 Installing Plugins (3 Methods)

**Method 1: Web GUI (Recommended for Beginners)**
```bash
# Start the plugin web interface
python3 aws_msp_plugin_web_gui.py

# Open browser to: http://localhost:5000
# Browse plugins, read descriptions, one-click install
```

**Method 2: Interactive Command Line**
```bash
# Launch interactive installer
./install-plugins.sh

# Follow prompts to select and install plugins
```

**Method 3: Direct Command Line**
```bash
# Install specific plugin
python3 aws_msp_plugin_manager.py --install-dir customer-monitoring-stack install aws-cloudwatch

# List all available plugins
python3 aws_msp_plugin_manager.py --install-dir customer-monitoring-stack list

# View plugins by category
python3 aws_msp_plugin_manager.py --install-dir customer-monitoring-stack list --category "AI/ML Features"
```

### Step 16: Popular Plugin Combinations for Dashboards

#### 16.1 AWS Integration Dashboard
**Plugins Needed:** `aws-cloudwatch`, `aws-discovery`, `cost-optimization`

**New Metrics Available:**
```
# AWS CloudWatch metrics
aws_ec2_cpu_utilization
aws_rds_connections
aws_lambda_invocations
aws_s3_bucket_size

# Cost optimization metrics  
aws_monthly_cost_estimate
aws_resource_utilization_score
aws_cost_anomaly_detected
```

**Dashboard Panels to Add:**
- AWS Resource Overview (EC2, RDS, Lambda status)
- Cost Tracking (monthly spend, cost per service)
- Resource Utilization (underused resources)

#### 16.2 Security Monitoring Dashboard
**Plugins Needed:** `saml-auth`, `cert-auth`, `network-security`, `crowdstrike-falcon`, `palo-alto-prisma`

**New Metrics Available:**
```
# Authentication metrics
saml_login_attempts
saml_login_failures
cert_auth_success_rate
cert_expiry_warnings

# Network security metrics
vpn_connection_count
network_intrusion_attempts
firewall_blocked_requests

# Security partner metrics
falcon_endpoint_detections
falcon_threat_score
prisma_firewall_blocks
prisma_threat_detections
```

**Dashboard Panels to Add:**
- Authentication Status (login success rates)
- Certificate Health (expiry warnings)
- Network Security Events (intrusion attempts)
- Endpoint Security (CrowdStrike detections)
- Firewall Activity (Palo Alto blocks)

#### 16.3 AI-Powered Monitoring Dashboard  
**Plugins Needed:** `anomaly-detection`, `predictive-alerts`

**New Metrics Available:**
```
# Anomaly detection metrics (from our demo)
anomaly_score_cpu_usage
anomaly_detected_memory_usage
predicted_response_time
confidence_score

# Predictive alerts
predicted_outage_probability
maintenance_recommendation_score
capacity_planning_forecast
```

**Dashboard Panels to Add:**
- Anomaly Detection Status (real-time anomaly scores)
- Prediction Timeline (what will happen next)
- AI Confidence Levels (how sure the AI is)

### Step 17: Plugin-Enhanced Dashboard Examples

#### 17.1 ELK Stack Integration Dashboard
**Plugin:** `log-aggregation`

**After installing ELK plugin, you get:**
- **Elasticsearch**: Log storage and search
- **Logstash**: Log processing pipeline  
- **Kibana**: Advanced log visualization

**New Dashboard Capabilities:**
```
# Log-based metrics now available
log_error_rate_per_minute
application_log_volume
security_log_alerts
performance_log_patterns
```

**Enhanced Panels:**
- Log Error Trends (errors over time from application logs)
- Security Event Timeline (security-related log entries)
- Application Performance Logs (response times from access logs)

#### 17.2 Business Intelligence Dashboard
**Plugin:** `business-intelligence`

**After installing BI plugin, you get:**
- **Data Warehouse**: Advanced analytics storage
- **BI Engine**: Custom dashboard creation
- **Executive Reporting**: Business-focused metrics

**New Dashboard Capabilities:**
```
# Business-focused metrics
customer_satisfaction_score
revenue_per_service
service_availability_sla
customer_impact_incidents
```

**Enhanced Panels:**
- SLA Compliance (uptime vs. contractual requirements)
- Customer Impact (how many customers affected by issues)
- Revenue Impact (cost of downtime)

#### 17.3 CMDB/ITSM Integration Dashboard
**Plugins:** `servicenow`, `bmc-helix`, `jira-service-mgmt`

**New Metrics for Change Management:**
```
# ServiceNow metrics
servicenow_incident_count
servicenow_change_requests
servicenow_sla_breaches

# BMC Helix metrics
bmc_remedy_tickets
bmc_change_approvals
bmc_cmdb_updates

# Jira Service Management metrics
jira_service_requests
jira_incident_resolution_time
jira_change_velocity
```

**ITSM Dashboard Panels:**
- Change Request Status (pending, approved, implemented)
- Incident Resolution Times (SLA compliance)
- CMDB Health (configuration accuracy)
- Service Request Volume (trends and patterns)

#### 17.5 AWS Support Integration Dashboard
**Plugin:** `aws-support`

**AWS Support Case Monitoring:**
```
# AWS Support Case Metrics
aws_support_open_cases
aws_support_case_severity_distribution
aws_support_response_time_sla
aws_support_resolution_time
aws_support_case_status_changes
aws_support_communication_count
```

**AWS Support Dashboard Panels:**
- Support Case Volume (open cases by severity)
- AWS Response SLA Compliance (response time vs. SLA)
- Case Resolution Trends (time to resolution by case type)
- Support Communication Activity (case updates and responses)
- Severity Distribution (critical, high, normal, low cases)

**MSP Partner Benefits:**
- Proactive customer communication about AWS issues
- Track AWS support performance for customer SLAs
- Correlate infrastructure problems with AWS support cases
- Monitor support case escalation patterns

#### 17.6 Ticketing Platform Integration Dashboard
**Plugins:** `zendesk`, `freshworks`, `linear`
**Plugins:** `splunk-enterprise`, `sumologic`, `datadog`

**New Metrics for Partner Platforms:**
```
# Splunk metrics
splunk_search_performance
splunk_index_volume
splunk_alert_count

# Sumo Logic metrics
sumologic_query_performance
sumologic_data_volume
sumologic_alert_triggers

# Datadog metrics
datadog_apm_traces
datadog_infrastructure_health
datadog_custom_metrics
```

**Partner Integration Panels:**
- Log Analysis Performance (Splunk/Sumo Logic query times)
- APM Trace Analysis (Datadog application performance)
- Cross-Platform Alert Correlation (unified view)

### Step 18: Plugin Management in Production

#### 18.1 Plugin Lifecycle Management
```bash
# Check installed plugins
python3 aws_msp_plugin_manager.py --install-dir customer-monitoring-stack list

# Update plugin (reinstall)
python3 aws_msp_plugin_manager.py --install-dir customer-monitoring-stack install aws-cloudwatch --force

# Remove plugin
python3 aws_msp_plugin_manager.py --install-dir customer-monitoring-stack uninstall aws-cloudwatch
```

#### 18.2 Plugin Dependencies
Some plugins depend on others:
- `predictive-alerts` requires `anomaly-detection`
- `auto-remediation` requires `predictive-alerts`
- `aws-discovery` requires `aws-cloudwatch`
- `auto-scaling` requires `prometheus-federation`

**The plugin manager automatically handles dependencies.**

#### 18.3 Plugin Configuration
Each plugin creates its own configuration files:
```
customer-monitoring-stack/
‚îú‚îÄ‚îÄ plugins/
‚îÇ   ‚îú‚îÄ‚îÄ aws-cloudwatch/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ aws-config.yml
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ cloudwatch-metrics.json
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ docker-compose.yml
‚îÇ   ‚îú‚îÄ‚îÄ anomaly-detection/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ml-config.yml
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ training-data.json
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ docker-compose.yml
```

**Customize plugin behavior by editing these config files.**

---

## üéì Conclusion: From Basic to Enterprise Monitoring

You've now learned:

### ‚úÖ **Basic Skills**
- Creating dashboards and panels
- Writing Prometheus queries
- Setting up alerts
- API integration

## üìä Part 12: Data Platform Integration (15 minutes)

### Step 12.1: Install Data Platform Plugins

```bash
# Install comprehensive data platform monitoring
python3 aws_msp_plugin_manager.py install redis
python3 aws_msp_plugin_manager.py install elasticsearch  
python3 aws_msp_plugin_manager.py install databricks
python3 aws_msp_plugin_manager.py install snowflake
python3 aws_msp_plugin_manager.py install mongodb
python3 aws_msp_plugin_manager.py install confluent
python3 aws_msp_plugin_manager.py install influxdb
python3 aws_msp_plugin_manager.py install clickhouse
python3 aws_msp_plugin_manager.py install neo4j
```

### Step 12.2: Create Data Platform Dashboard

1. **Create New Dashboard**: "Data Platform Monitoring"
2. **Add Redis Panel**:
   - **Query**: `redis_connected_clients`
   - **Title**: "Redis Connections"
   - **Type**: Time series

3. **Add Elasticsearch Panel**:
   - **Query**: `elasticsearch_cluster_health`
   - **Title**: "Elasticsearch Health"
   - **Type**: Stat

4. **Add MongoDB Panel**:
   - **Query**: `mongodb_operations_per_second`
   - **Title**: "MongoDB Operations/sec"
   - **Type**: Time series

5. **Add Kafka Panel**:
   - **Query**: `confluent_consumer_lag`
   - **Title**: "Kafka Consumer Lag"
   - **Type**: Time series

6. **Add Database Performance Panel**:
   - **Query A**: `snowflake_query_performance`
   - **Query B**: `clickhouse_query_latency`
   - **Query C**: `neo4j_query_performance`
   - **Title**: "Database Query Performance"
   - **Type**: Time series

### Step 12.3: Configure Data Platform Alerts

```bash
# Set up data platform alerting
curl -X POST http://localhost:9090/api/v1/rules \
  -H "Content-Type: application/json" \
  -d '{
    "groups": [{
      "name": "data_platform_alerts",
      "rules": [
        {
          "alert": "RedisHighMemoryUsage",
          "expr": "redis_used_memory_bytes > 1000000000",
          "for": "5m",
          "labels": {"severity": "warning"},
          "annotations": {"summary": "Redis memory usage is high"}
        },
        {
          "alert": "ElasticsearchClusterDown",
          "expr": "elasticsearch_cluster_health < 1",
          "for": "2m",
          "labels": {"severity": "critical"},
          "annotations": {"summary": "Elasticsearch cluster is unhealthy"}
        },
        {
          "alert": "KafkaConsumerLag",
          "expr": "confluent_consumer_lag > 1000",
          "for": "5m",
          "labels": {"severity": "warning"},
          "annotations": {"summary": "Kafka consumer lag is high"}
        }
      ]
    }]
  }'
```

### ‚úÖ **What You've Learned**

### ‚úÖ **Advanced Skills**  
- Plugin system architecture
- Multi-service monitoring
- AI-powered anomaly detection
- Business intelligence integration

### ‚úÖ **Enterprise Skills**
- Security monitoring
- Cost optimization
- Predictive analytics
- Auto-remediation

### üöÄ **Next Steps**
1. **Start Simple**: Deploy base stack, create basic CPU/memory dashboards
2. **Add Plugins**: Install AWS CloudWatch plugin for cloud integration
3. **Enhance Security**: Add SAML authentication and certificate monitoring
4. **Enable AI**: Install anomaly detection for intelligent monitoring
5. **Scale Up**: Add federation and HA plugins for enterprise deployment

**Your monitoring stack can grow from basic system metrics to a full enterprise observability platform - all through the modular plugin system!**
